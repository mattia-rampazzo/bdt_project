{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NYNm8x-LBI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Title: Building a Synthetic Medical Dataset for Health Condition Analysis Using Machine Learning\n",
        "\n",
        "Abstract:\n",
        "The increasing need for large, comprehensive datasets in health condition analysis often collides with stringent restrictions on accessing real medical data, especially for non-medical students. This report presents a methodology for constructing a synthetic dataset by integrating multiple publicly available datasets, enhancing them with additional variables through machine learning techniques, and generating a large-scale synthetic dataset using Conditional Tabular Generative Adversarial Networks (CTGAN). Our approach primarily utilized the Asthma Disease Dataset as the base, with the Classification of Coronary Artery Disease (CAD) Dataset providing supplementary cardiac variables. This document details the dataset integration, cleaning processes, model testing, and synthetic data generation.\n",
        "\n",
        "# 1. Introduction\n",
        "\n",
        "For this project, our objective was to create a synthetic dataset that models various health conditions and risk factors. However, our attempts to gain access to more comprehensive and detailed datasets from specialized sources were unsuccessful due to restrictions and delays in the approval process. To circumvent these challenges, we turned to publicly available datasets on platforms such as Kaggle, understanding that these might not fully encompass all the variables required for our analysis.\n",
        "\n",
        "In this context, we aimed to build a synthetic dataset that models asthma and its interaction with cardiac variables, among other health factors. To achieve this, we selected the Asthma Disease Dataset and the Classification of Coronary Artery Disease Dataset from Kaggle. We employed machine learning techniques to integrate and augment these datasets, followed by the application of CTGAN to generate a large-scale synthetic dataset.\n",
        "\n",
        "# 2. Core Datasets and Integration\n",
        "\n",
        "The foundation of our synthetic dataset was the Asthma Disease Dataset https://www.kaggle.com/datasets/rabieelkharoua/asthma-disease-dataset, a robust and detailed collection of data concerning asthma patients. This dataset was chosen due to its comprehensive coverage of variables related to respiratory health, which aligned with our project’s objectives.\n",
        "\n",
        "However, to enrich the dataset and include cardiac variables, we integrated data from the Classification of Coronary Artery Disease (CAD) Dataset https://www.google.com/url?q=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fsaeedeheydarian%2Fclassification-of-coronary-artery-disease. This dataset provided critical variables related to coronary health, which are essential for understanding the interactions between asthma and cardiac conditions. The integration process involved the following steps:\n",
        "\n",
        "Variable Matching and Alignment: Ensuring that the variables from both datasets were compatible, with consistent data types and ranges.\n",
        "Data Augmentation: Using machine learning models to predict missing variables and fill gaps in the data.\n",
        "Data Merging: Combining the datasets into a unified structure that could be used as a basis for further analysis and synthetic data generation.\n",
        "# 3. Challenges in Data Integration and Augmentation\n",
        "\n",
        "One of the major challenges in this project was the heterogeneity of the datasets. The Asthma and CAD datasets had different structures and variable distributions, making it difficult to merge them seamlessly. To address these issues, we tested several machine learning models to predict and align variables, ensuring that the final integrated dataset was coherent and comprehensive.\n",
        "\n",
        "Additionally, we encountered issues with missing data, particularly in the CAD dataset. To resolve this, we employed imputation techniques and used machine learning to estimate missing values, particularly for variables that are critical for predicting health outcomes, such as age, BMI, and blood pressure.\n",
        "\n",
        "# 4. Addressing the Challenges of Pollen Allergy Data\n",
        "\n",
        "In constructing a comprehensive synthetic dataset for asthma and related respiratory conditions, one of the major hurdles was the incorporation of specific pollen allergy data. Pollen allergies play a significant role in the exacerbation of asthma symptoms, and understanding the relationship between pollen exposure and allergic reactions is crucial for accurate modeling. However, obtaining datasets that not only capture the presence of specific pollen allergies (e.g., ragweed, grass, birch) but also detail the severity of these allergies and their interaction with varying pollen concentrations presented several challenges.\n",
        "\n",
        "The primary difficulties were:\n",
        "\n",
        "Lack of Detailed Allergic Response Data:\n",
        "Publicly available datasets often include general information about pollen exposure but fall short of providing specific details on the allergic responses of individuals to different types of pollen. This includes data on the severity of the allergic reactions, which is essential for understanding how different concentrations of pollen influence the health outcomes of individuals with asthma.\n",
        "Inconsistent Measurement of Pollen Concentrations:\n",
        "While some datasets provide data on pollen counts, the variability in how these counts are measured and reported across different studies and regions made it challenging to integrate them into a cohesive model. Moreover, datasets that linked pollen concentrations directly to health outcomes were scarce, making it difficult to draw definitive conclusions about the impact of pollen exposure on allergy severity and asthma exacerbation.\n",
        "Lack of Granular Data Linking Pollen Types to Specific Allergic Reactions:\n",
        "Another significant gap was the absence of datasets that detailed how specific types of pollen (e.g., ragweed, grass, birch) correlated with particular allergic reactions. This type of data is crucial for accurately modeling the influence of different pollen types on asthma severity, yet it was not readily available in the datasets we initially considered.\n",
        "To address these challenges, we leveraged Academic Research and Published Data: We utilized estimates and models from academic research to simulate realistic pollen exposure levels, particularly focusing on the severity of allergic responses to different pollen types. This included insights from studies published in allergy and immunology journals, which helped guide our assumptions for generating synthetic data. Our sources are:\n",
        "https://www.meduniwien.ac.at/web/en/ueber-uns/news/2022/news-im-august-2022/ragweed-allergie-herkunftsort-und-umwelt-beeinflussen-aggressivitaet-der-pollen/\n",
        "https://www.meduniwien.ac.at/web/en/about-us/news/detailsite/2018/news-jaenner-2018/first-vaccine-in-the-world-developed-against-grass-pollen-allergy/medicine-science/\n",
        "https://www.thermofisher.com/allergy/us/en/allergen-fact-sheets/mugwort.html 10-15% in EU\n",
        "https://www.meduniwien.ac.at/web/en/about-us/news/detailsite/apple-allergy-symptoms-may-be-significantly-reduced-in-future/ 4.73%\n",
        "https://www.thermofisher.com/phadia/wo/en/resources/allergen-encyclopedia/t2.html 6-10%%\n",
        "http://www.globalasthmareport.org/\n",
        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5806141/\n",
        "\n",
        "\n",
        "##Pollen Exposure Index (PEI) and Pollen Weighting:\n",
        "* The impact of various pollen types on allergic conditions, such as allergic rhinitis and asthma, has been well documented in the Allergic Rhinitis and its Impact on Asthma (ARIA) guidelines published by the World Health Organization (WHO). These guidelines provide a framework for understanding how different pollen types affect individuals with allergies and asthma. The weights assigned to different pollen types in the PEI calculation reflect their relative impact based on these guidelines.\n",
        "##Air Quality Impact Index (AQII):\n",
        "* The calculation of the AQII is based on the air quality guidelines provided by the World Health Organization (WHO) and the United States Environmental Protection Agency (EPA). These organizations have set thresholds for various pollutants, such as PM10, PM2.5, nitrogen dioxide (NO2), sulfur dioxide (SO2), carbon monoxide (CO), and ozone. The scores in the code are scaled according to these thresholds to reflect the health impact of exposure to these pollutants. The WHO's \"Global Air Quality Guidelines\" (2021) were particularly instrumental in defining these thresholds.\n",
        "##Ozone-Pollen Interaction Index (OPII):\n",
        "* The interaction between ozone levels and pollen allergenicity has been highlighted in research studies such as Bousquet et al., where it is noted that ozone can increase the allergenicity of pollen, exacerbating allergic symptoms. This insight was used to adjust the OPII based on ozone concentrations.\n",
        "##Particulate Matter Health Index (PMHI):\n",
        "* The health risks associated with particulate matter, particularly PM2.5 and PM10, are well-documented in numerous studies, including those published by the WHO and the EPA. PM2.5, being smaller, penetrates deeper into the lungs and is associated with more severe health effects, which is why it is weighted more heavily in the PMHI calculation.\n",
        "##Composite Environmental Risk Index (CERI):\n",
        "* The CERI is a composite index that aggregates the total environmental risk from various factors, including pollen exposure, air quality, and particulate matter. This approach is in line with multi-factorial health risk assessment frameworks used by public health organizations. The normalization of the total score to a 0-1 scale ensures that the risk is presented in an intuitive format for users.\n",
        "##Health Conditions and Personalized Recommendations:\n",
        "* The code incorporates personalized recommendations based on the user's health conditions, such as asthma, hay fever, eczema, and coronary artery disease (CAD). The increased risk for these conditions in polluted or high-pollen environments is supported by extensive literature, including the Global Initiative for Asthma (GINA)guidelines and studies on the \"atopic march\" in allergic diseases. The code's logic reflects the heightened sensitivity of individuals with these conditions to environmental factors, guiding them to take appropriate precautions based on the computed risk score.\n",
        "* Specifically, the recommendations for individuals with CAD are influenced by guidelines from the American Heart Association (AHA), which emphasize the importance of avoiding poor air quality and high physical exertion in environments with elevated pollutant levels.\n",
        "\n",
        "# 5. Synthetic Data Generation Using CTGAN\n",
        "\n",
        "With the integrated dataset in place, we moved to the synthetic data generation phase. For this, we chose the Conditional Tabular GAN (CTGAN) model, which is particularly well-suited for handling the complexities of tabular data. The reasons for selecting CTGAN include:\n",
        "\n",
        "##Introduction to Synthetic Data Generation in tabular datasets\n",
        "One of the most advanced and effective methods for synthetic data generation in tabular datasets is the use of Generative Adversarial Networks (GANs), particularly the Conditional Tabular GAN (CTGAN). This chapter outlines the reasons for choosing CTGAN for synthetic data generation in our project, discusses its methodological strengths, and explains why it is a superior approach compared to traditional methods.\n",
        "##Overview of CTGAN\n",
        "CTGAN (Conditional Tabular GAN) is a variant of GANs specifically designed to handle the unique challenges posed by tabular data. Traditional GANs have been highly successful in generating synthetic data for images and text but struggle when applied directly to tabular data due to the discrete and often imbalanced nature of features in such datasets.\n",
        "CTGAN addresses these challenges by incorporating a conditional mechanism that allows it to model both continuous and discrete variables effectively. It was developed to overcome the shortcomings of earlier models, such as inability to accurately capture the dependencies between variables in tabular data and poor performance on imbalanced datasets.\n",
        "##Why CTGAN is an Ideal Choice\n",
        "Handling Mixed Data Types: Tabular data often includes a mix of continuous and categorical variables, which can be difficult to model simultaneously. CTGAN uses a technique called mode-specific normalization to transform continuous variables and applies a Gumbel-softmax trick to handle categorical variables. This allows CTGAN to maintain the relationships between these different data types, generating realistic synthetic data that accurately reflects the underlying patterns in the original dataset. Capturing Complex Dependencies: In health-related datasets, such as the ones used in this project, variables can exhibit complex interdependencies (e.g., age, BMI, and gender influencing health outcomes). CTGAN’s conditional mechanism allows it to learn and preserve these dependencies, ensuring that the synthetic data maintains the integrity of the original data’s relationships. This is particularly important for tasks such as predictive modeling, where the accuracy of the model relies heavily on the quality of the input data. Effective Management of Imbalanced Data: Many real-world datasets suffer from imbalanced classes, where certain outcomes or categories are underrepresented. Traditional synthetic data generation methods may amplify these imbalances, leading to biased models. CTGAN, however, is designed to handle imbalances more effectively by focusing on the minority classes during training, ensuring that the synthetic data is more balanced and representative of the underlying population. Preservation of Privacy: One of the primary motivations for using synthetic data is to protect the privacy of individuals in the dataset. CTGAN generates new data points that are statistically similar to the original data but do not directly replicate any individual’s records. This makes CTGAN an excellent choice for projects that require data sharing or analysis without compromising privacy. Flexibility and Adaptability: CTGAN is highly flexible and can be adapted to different types of tabular data across various domains. Its architecture allows for the inclusion of additional features or modifications to the generation process, making it a versatile tool in the synthetic data generation toolkit. State-of-the-Art Performance: Numerous studies and experiments have demonstrated that CTGAN outperforms other synthetic data generation methods in terms of both the realism of the generated data and the preservation of statistical properties. This has made CTGAN a preferred choice in academic and industrial applications where the accuracy and utility of synthetic data are paramount.\n",
        "##Application in the Current Project\n",
        "In this project, CTGAN was chosen to generate synthetic data based on the integrated health datasets described earlier. The ability of CTGAN to handle mixed data types and maintain complex dependencies was critical in ensuring that the generated data was both realistic and useful for downstream predictive modeling tasks. By using CTGAN, we were able to overcome the limitations of incomplete datasets and enhance our dataset with additional synthetic records that closely mimic the statistical properties of the original data.\n",
        "The synthetic data generated by CTGAN will serve as a valuable resource for training machine learning models, enabling robust predictions while safeguarding the privacy of the individuals represented in the original datasets.\n",
        "\n",
        "# 6. Data Cleaning and Validation\n",
        "\n",
        "After generating the synthetic dataset, we performed an extensive data cleaning process. This involved:\n",
        "\n",
        "Removing Noise and Outliers: Identifying and eliminating anomalous data points that could skew the analysis.\n",
        "Ensuring Consistency: Verifying that the synthetic data maintained the statistical properties and distributions of the original data.\n",
        "Validation: Comparing the synthetic data with the original dataset to assess its accuracy and fidelity. This step was crucial to ensure that the synthetic data could be reliably used for predictive modeling and analysis.\n",
        "\n",
        "# 7. Application and Future Work\n",
        "\n",
        "The synthetic dataset generated through this process is a valuable resource for training machine learning models, conducting epidemiological studies, and developing predictive tools. In future work, this dataset could be expanded by integrating additional health conditions or environmental factors, such as pollen exposure, to provide an even more comprehensive tool for health analysis.\n",
        "Although not perfect this dataset present an interesting structure that if replicated with more complex and complete dataset could perform way better.\n",
        "\n",
        "#8. Conclusion\n",
        "\n",
        "The creation of a synthetic medical dataset using publicly available data and machine learning techniques is a powerful approach to circumventing the challenges of data accessibility. By carefully selecting and integrating datasets, augmenting variables with predictive models, and employing advanced synthetic data generation techniques like CTGAN, we have constructed a dataset that can serve as a robust foundation for further research in health condition analysis."
      ],
      "metadata": {
        "id": "Sth1IO3LV2kz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtm7p2njtKpb",
        "outputId": "215dd2b4-a0f6-4801-8e49-6b7bef40cc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ctgan in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.10/dist-packages (from ctgan) (4.66.5)\n",
            "Requirement already satisfied: rdt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan) (1.12.3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from ctgan) (2.0.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from ctgan) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->ctgan) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->ctgan) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->ctgan) (2024.1)\n",
            "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.11.0->ctgan) (27.0.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.11.0->ctgan) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.11.0->ctgan) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan) (12.6.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->ctgan) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.11.0->ctgan) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.11.0->ctgan) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan) (1.3.0)\n",
            "Requirement already satisfied: table_evaluator in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas==2.0.* in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (5.9.5)\n",
            "Requirement already satisfied: dython==0.7.3 in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (0.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from table_evaluator) (1.13.1)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from dython==0.7.3->table_evaluator) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.*->table_evaluator) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.*->table_evaluator) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.*->table_evaluator) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->table_evaluator) (3.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->table_evaluator) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->table_evaluator) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.*->table_evaluator) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#to run this notebook you will have to have the following libraries: ctgan, pandas, numpy, table_evaluator, sklearn\n",
        "!pip install ctgan\n",
        "!pip install table_evaluator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbZZWXdAt_y8",
        "outputId": "4acfb334-be4b-451c-e1a8-15c32a0b1135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file paths as variables\n",
        "asthma_dataset_path = '/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/asthma_disease_data.csv'\n",
        "cad_dataset_path = '/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/CAD.csv'\n",
        "\n",
        "# Load the datasets into separate DataFrames\n",
        "asthmaOriginal_df = pd.read_csv(asthma_dataset_path)\n",
        "cadOriginal_df = pd.read_csv(cad_dataset_path)\n",
        "\n",
        "# Work on copies of the datasets to avoid modifying the originals\n",
        "asthmadf = asthmaOriginal_df.copy()\n",
        "caddf = cadOriginal_df.copy()\n",
        "\n",
        "# Optional: If loading datasets from GitHub\n",
        "# Replace the URLs below with the actual GitHub raw file links\n",
        "\n",
        "#asthma_github_url = 'https://raw.githubusercontent.com/username/repository/branch/path_to_asthma_data.csv'\n",
        "#cad_github_url = 'https://raw.githubusercontent.com/username/repository/branch/path_to_cad_data.csv'\n",
        "\n",
        "# Load the datasets from GitHub\n",
        "#asthma_df_github = pd.read_csv(asthma_github_url)\n",
        "#cad_df_github = pd.read_csv(cad_github_url)\n",
        "\n",
        "# Work on copies of the datasets loaded from GitHub\n",
        "#asthma_df_github_copy = asthma_df_github.copy()\n",
        "#cad_df_github_copy = cad_df_github.copy()\n"
      ],
      "metadata": {
        "id": "18E8szm0uIxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Caddf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "caddf = caddf.dropna()\n",
        "\n",
        "# Correct the BMI column by converting to numeric values\n",
        "caddf['BMI'] = caddf['BMI'].round(1)\n",
        "# Correct the 'Sex' column\n",
        "caddf['Sex'] = caddf['Sex'].replace({'Fmale': 'Female'})\n",
        "\n",
        "\n",
        "\n",
        "# Display the data types and first few rows after the initial correction\n",
        "caddf.dtypes, caddf.head()\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in ['Sex', 'Obesity', 'Airway disease', 'Thyroid Disease', 'Cath']:\n",
        "    le = LabelEncoder()\n",
        "    caddf[column] = le.fit_transform(caddf[column])\n",
        "    label_encoders[column] = le\n",
        "# Rename the columns in caddf\n",
        "caddf.rename(columns={'Age': 'age', 'Sex': 'gender', 'BMI': 'bmi', 'Cath': 'Cad'}, inplace=True)"
      ],
      "metadata": {
        "id": "0vRYzgYcuqiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = caddf[features]\n",
        "y = caddf[target]\n",
        "\n",
        "# Check for missing values and handle them if necessary\n",
        "if X.isnull().sum().any():\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCTzeG8ivb_m",
        "outputId": "692e97ce-ff29-4b2b-b9cd-8d2ddeaa3fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.71\n",
            "Precision: 0.48\n",
            "Recall: 0.48\n",
            "ROC-AUC Score: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize Grid Search\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit Grid Search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from Grid Search\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, best_rf_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DZs1ELFFzzdj",
        "outputId": "316a6b82-b38e-4bc7-a62b-6b2f000558cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-723509759d4d>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Best parameters from Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     )\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after some tests it appeared that the data weren't enough so we decided to apply ctgan to create synthetic data and see if there are improvements on the model assesments\n",
        "\n"
      ],
      "metadata": {
        "id": "7dUIhYjE1RAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#starting generation of synthetic data to have a sufficient number of subjects to work with other datasets\n",
        "from ctgan import CTGAN\n",
        "features = [\n",
        "    'age',\n",
        "    'Weight',\n",
        "    'Length',\n",
        "    'gender',\n",
        "    'bmi',\n",
        "    'DM',\n",
        "    'HTN',\n",
        "    'Current Smoker',\n",
        "    'EX-Smoker',\n",
        "    'FH',\n",
        "    'Obesity',\n",
        "    'CRF',\n",
        "    'CVA',\n",
        "    'Airway disease',\n",
        "    'Thyroid Disease',\n",
        "    'CHF',\n",
        "    'DLP',\n",
        "    'BP',\n",
        "    'PR',\n",
        "    'Edema',\n",
        "    'Weak Peripheral Pulse',\n",
        "    'Lung rales',\n",
        "    'Systolic Murmur',\n",
        "    'Diastolic Murmur',\n",
        "    'Typical Chest Pain',\n",
        "    'Dyspnea',\n",
        "    'Function Class',\n",
        "    'Atypical',\n",
        "    'Nonanginal',\n",
        "    'Exertional CP',\n",
        "    'LowTH Ang',\n",
        "    'Q Wave',\n",
        "    'St Elevation',\n",
        "    'St Depression',\n",
        "    'Tinversion',\n",
        "    'LVH',\n",
        "    'Poor R Progression',\n",
        "    'FBS',\n",
        "    'CR',\n",
        "    'TG',\n",
        "    'LDL',\n",
        "    'HDL',\n",
        "    'BUN',\n",
        "    'ESR',\n",
        "    'HB',\n",
        "    'K',\n",
        "    'Na',\n",
        "    'WBC',\n",
        "    'Lymph',\n",
        "    'Neut',\n",
        "    'PLT',\n",
        "    'EF-TTE',\n",
        "    'Region RWMA',\n",
        "    'VHD',\n",
        "    'Cad'\n",
        "]\n",
        "\n",
        "# Drop rows with missing BMI values\n",
        "startingdf = caddf.dropna(subset=['bmi'])\n",
        "\n",
        "# Initialize CTGAN\n",
        "ctgan = CTGAN(verbose=True)\n",
        "\n",
        "# Fit CTGAN to the data\n",
        "ctgan.fit(startingdf, features, epochs=5000)  # Adjust the number of epochs as needed MAYBE RUN MORE LIKE 50000 epochs\n",
        "\n",
        "# Generate 200 synthetic samples\n",
        "samples = ctgan.sample(10000)\n",
        "\n",
        "# Post-process the synthetic data to ensure 'gender' is correctly encoded\n",
        "samples['gender'] = samples['gender'].clip(0, 1).round().astype(int)\n",
        "\n",
        "# Optionally, print or inspect the first few rows of the synthetic data\n",
        "print(samples.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G0XeSFy1wCL",
        "outputId": "5ac7216f-5dd1-4102-8126-887b8fcd5e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gen. (0.00) | Discrim. (0.00):   0%|          | 0/5000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Gen. (-0.77) | Discrim. (-0.51): 100%|██████████| 5000/5000 [08:37<00:00,  9.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  Weight  Length  gender   bmi  DM  HTN  Current Smoker  EX-Smoker  FH  \\\n",
            "0   57      66     170       1  26.3   0    0               0          0   0   \n",
            "1   72      78     175       1  24.3   1    1               1          0   0   \n",
            "2   56      63     162       1  25.1   1    0               0          0   0   \n",
            "3   63      84     175       1  27.4   0    1               1          0   0   \n",
            "4   49      81     155       0  28.4   0    0               0          0   1   \n",
            "\n",
            "   ...    K   Na    WBC  Lymph  Neut  PLT EF-TTE  Region RWMA       VHD  Cad  \n",
            "0  ...  3.4  146   6900     37    60  174     55            0      mild    1  \n",
            "1  ...  4.7  139  10000     29    65  192     50            0      mild    1  \n",
            "2  ...  4.6  142   8500     34    54  290     50            0  Moderate    0  \n",
            "3  ...  4.8  153   9400     15    67  170     40            3      mild    0  \n",
            "4  ...  4.3  138   6900     36    40  236     55            2         N    1  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples.to_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/CADSynthetic.csv', index=False)"
      ],
      "metadata": {
        "id": "fuReuZcA5aqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples.dtypes, samples.head(), len(samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZMLaYej5lXn",
        "outputId": "791c35c2-f0d7-49ed-a692-892219c32ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(age                        int64\n",
              " Weight                     int64\n",
              " Length                     int64\n",
              " gender                     int64\n",
              " bmi                      float64\n",
              " DM                         int64\n",
              " HTN                        int64\n",
              " Current Smoker             int64\n",
              " EX-Smoker                  int64\n",
              " FH                         int64\n",
              " Obesity                    int64\n",
              " CRF                       object\n",
              " CVA                       object\n",
              " Airway disease             int64\n",
              " Thyroid Disease            int64\n",
              " CHF                       object\n",
              " DLP                       object\n",
              " BP                         int64\n",
              " PR                         int64\n",
              " Edema                      int64\n",
              " Weak Peripheral Pulse     object\n",
              " Lung rales                object\n",
              " Systolic Murmur           object\n",
              " Diastolic Murmur          object\n",
              " Typical Chest Pain         int64\n",
              " Dyspnea                   object\n",
              " Function Class             int64\n",
              " Atypical                  object\n",
              " Nonanginal                object\n",
              " Exertional CP             object\n",
              " LowTH Ang                 object\n",
              " Q Wave                     int64\n",
              " St Elevation               int64\n",
              " St Depression              int64\n",
              " Tinversion                 int64\n",
              " LVH                       object\n",
              " Poor R Progression        object\n",
              " FBS                        int64\n",
              " CR                       float64\n",
              " TG                         int64\n",
              " LDL                        int64\n",
              " HDL                      float64\n",
              " BUN                        int64\n",
              " ESR                        int64\n",
              " HB                       float64\n",
              " K                        float64\n",
              " Na                         int64\n",
              " WBC                        int64\n",
              " Lymph                      int64\n",
              " Neut                       int64\n",
              " PLT                        int64\n",
              " EF-TTE                     int64\n",
              " Region RWMA                int64\n",
              " VHD                       object\n",
              " Cad                        int64\n",
              " dtype: object,\n",
              "    age  Weight  Length  gender   bmi  DM  HTN  Current Smoker  EX-Smoker  FH  \\\n",
              " 0   57      66     170       1  26.3   0    0               0          0   0   \n",
              " 1   72      78     175       1  24.3   1    1               1          0   0   \n",
              " 2   56      63     162       1  25.1   1    0               0          0   0   \n",
              " 3   63      84     175       1  27.4   0    1               1          0   0   \n",
              " 4   49      81     155       0  28.4   0    0               0          0   1   \n",
              " \n",
              "    ...    K   Na    WBC  Lymph  Neut  PLT EF-TTE  Region RWMA       VHD  Cad  \n",
              " 0  ...  3.4  146   6900     37    60  174     55            0      mild    1  \n",
              " 1  ...  4.7  139  10000     29    65  192     50            0      mild    1  \n",
              " 2  ...  4.6  142   8500     34    54  290     50            0  Moderate    0  \n",
              " 3  ...  4.8  153   9400     15    67  170     40            3      mild    0  \n",
              " 4  ...  4.3  138   6900     36    40  236     55            2         N    1  \n",
              " \n",
              " [5 rows x 55 columns],\n",
              " 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "samples = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/CADSynthetic.csv')\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Check for missing values and handle them if necessary\n",
        "if X.isnull().sum().any():\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBQ8Hjtd6Djd",
        "outputId": "ec49c760-6399-4b10-974e-84eca37a8efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.70\n",
            "Precision: 0.46\n",
            "Recall: 0.35\n",
            "ROC-AUC Score: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize Grid Search\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit Grid Search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from Grid Search\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, best_rf_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ricdVOKR7qcH",
        "outputId": "5dd6e64d-3c9a-467a-e7b2-a68f4091febd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-723509759d4d>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Best parameters from Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     )\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    encoder = LabelEncoder()\n",
        "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model name for identification\n",
        "model_name = \"LightGBM_CAD_v1\"\n",
        "\n",
        "# Initialize and train the LightGBM model\n",
        "model = lgb.LGBMClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = f\"{model_name}_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_krZOUb5_IBO",
        "outputId": "a55051fe-836a-4dcf-9890-0bee42bea278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 1937, number of negative: 5063\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 181\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.276714 -> initscore=-0.960819\n",
            "[LightGBM] [Info] Start training from score -0.960819\n",
            "Model: LightGBM_CAD_v1\n",
            "Accuracy: 0.74\n",
            "Precision: 0.58\n",
            "Recall: 0.26\n",
            "ROC-AUC Score: 0.71\n",
            "Model saved as LightGBM_CAD_v1_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    encoder = LabelEncoder()\n",
        "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model name for identification\n",
        "model_name = \"XGBoost_CAD_v1\"\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = f\"{model_name}_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7bKfoES_hwE",
        "outputId": "abb3e13d-3f75-4b87-9a13-3ba3cc79a860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: XGBoost_CAD_v1\n",
            "Accuracy: 0.73\n",
            "Precision: 0.52\n",
            "Recall: 0.32\n",
            "ROC-AUC Score: 0.70\n",
            "Model saved as XGBoost_CAD_v1_model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:17:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Load the dataset\n",
        "samples = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/CADSynthetic.csv')\n",
        "\n",
        "# Define relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    encoder = LabelEncoder()\n",
        "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Create interaction and polynomial features\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Get the names of the new features\n",
        "poly_features = poly.get_feature_names_out(features)\n",
        "\n",
        "# Convert to DataFrame for better readability\n",
        "X_poly_df = pd.DataFrame(X_poly, columns=poly_features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly_df, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model name for identification\n",
        "model_name = \"RandomForest_Poly_CAD_v1\"\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = f\"{model_name}_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTwBGd5oA0Dy",
        "outputId": "36090841-e4ce-435e-866f-f33b2974db59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest_Poly_CAD_v1\n",
            "Accuracy: 0.70\n",
            "Precision: 0.46\n",
            "Recall: 0.36\n",
            "ROC-AUC Score: 0.66\n",
            "Model saved as RandomForest_Poly_CAD_v1_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    encoder = LabelEncoder()\n",
        "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model name for identification\n",
        "model_name = \"RandomForest_Balanced_CAD_v1\"\n",
        "\n",
        "# Initialize and train the Random Forest model with class_weight='balanced'\n",
        "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = f\"{model_name}_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2K5NoaRBKw5",
        "outputId": "7e19811b-00a5-4f34-a2c1-9249fe0125e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForest_Balanced_CAD_v1\n",
            "Accuracy: 0.69\n",
            "Precision: 0.43\n",
            "Recall: 0.39\n",
            "ROC-AUC Score: 0.65\n",
            "Model saved as RandomForest_Balanced_CAD_v1_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "import joblib  # For saving the model\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "target = 'Cad'\n",
        "\n",
        "# Extract the features and target variable from the dataset\n",
        "X = samples[features]\n",
        "y = samples[target]\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    encoder = LabelEncoder()\n",
        "    X[col] = encoder.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model name for identification\n",
        "model_name = \"LightGBM_CAD_v2\"\n",
        "\n",
        "# Initialize and train the LightGBM model\n",
        "model = lgb.LGBMClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model_filename = f\"{model_name}_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhUXulIVGZfb",
        "outputId": "c5e9dc54-b358-42ca-b6ee-95056a6ebd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 1937, number of negative: 5063\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 181\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.276714 -> initscore=-0.960819\n",
            "[LightGBM] [Info] Start training from score -0.960819\n",
            "Model: LightGBM_CAD_v2\n",
            "Accuracy: 0.74\n",
            "Precision: 0.58\n",
            "Recall: 0.26\n",
            "ROC-AUC Score: 0.71\n",
            "Model saved as LightGBM_CAD_v2_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caddf.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5kfpvaSCLLst",
        "outputId": "7cbe2fcd-93aa-46e4-ed11-dcd75bb8698b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                        int64\n",
              "Weight                     int64\n",
              "Length                     int64\n",
              "gender                     int64\n",
              "bmi                      float64\n",
              "DM                         int64\n",
              "HTN                        int64\n",
              "Current Smoker             int64\n",
              "EX-Smoker                  int64\n",
              "FH                         int64\n",
              "Obesity                    int64\n",
              "CRF                       object\n",
              "CVA                       object\n",
              "Airway disease             int64\n",
              "Thyroid Disease            int64\n",
              "CHF                       object\n",
              "DLP                       object\n",
              "BP                         int64\n",
              "PR                         int64\n",
              "Edema                      int64\n",
              "Weak Peripheral Pulse     object\n",
              "Lung rales                object\n",
              "Systolic Murmur           object\n",
              "Diastolic Murmur          object\n",
              "Typical Chest Pain         int64\n",
              "Dyspnea                   object\n",
              "Function Class             int64\n",
              "Atypical                  object\n",
              "Nonanginal                object\n",
              "Exertional CP             object\n",
              "LowTH Ang                 object\n",
              "Q Wave                     int64\n",
              "St Elevation               int64\n",
              "St Depression              int64\n",
              "Tinversion                 int64\n",
              "LVH                       object\n",
              "Poor R Progression        object\n",
              "FBS                        int64\n",
              "CR                       float64\n",
              "TG                         int64\n",
              "LDL                        int64\n",
              "HDL                      float64\n",
              "BUN                        int64\n",
              "ESR                        int64\n",
              "HB                       float64\n",
              "K                        float64\n",
              "Na                         int64\n",
              "WBC                        int64\n",
              "Lymph                      int64\n",
              "Neut                       int64\n",
              "PLT                        int64\n",
              "EF-TTE                     int64\n",
              "Region RWMA                int64\n",
              "VHD                       object\n",
              "Cad                        int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Length</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DM</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HTN</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Current Smoker</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EX-Smoker</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FH</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obesity</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRF</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CVA</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airway disease</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thyroid Disease</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHF</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DLP</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BP</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PR</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edema</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weak Peripheral Pulse</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lung rales</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Systolic Murmur</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diastolic Murmur</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Typical Chest Pain</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dyspnea</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Function Class</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atypical</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nonanginal</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exertional CP</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LowTH Ang</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q Wave</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>St Elevation</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>St Depression</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tinversion</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVH</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Poor R Progression</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FBS</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CR</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TG</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LDL</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDL</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BUN</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESR</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HB</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WBC</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lymph</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neut</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PLT</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EF-TTE</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Region RWMA</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VHD</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cad</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rename columns\n",
        "asthmadf.rename(columns={'Age': 'age', 'Gender': 'gender', 'BMI': 'bmi', 'Smoking': 'Current Smoker'}, inplace=True)\n",
        "\n",
        "# Reduce to 1 decimal the bmi\n",
        "asthmadf['bmi'] = asthmadf['bmi'].round(1)\n",
        "\n",
        "\n",
        "# Create the Obesity column\n",
        "if 'bmi' in asthmadf.columns:\n",
        "    asthmadf['Obesity'] = asthmadf['bmi'].apply(lambda x: 0 if x > 25 else 1 ) #0 yes 1 no\n",
        "else:\n",
        "    print(\"Error: 'BMI' column is missing in the StartingDataset.\")"
      ],
      "metadata": {
        "id": "eHbsDuD8Go7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asthmadf.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AHsj8UwT7Zhr",
        "outputId": "e3db23da-a42d-4c2b-d6a9-cd006aeac92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatientID                   int64\n",
              "age                         int64\n",
              "gender                      int64\n",
              "Ethnicity                   int64\n",
              "EducationLevel              int64\n",
              "bmi                       float64\n",
              "Current Smoker              int64\n",
              "PhysicalActivity          float64\n",
              "DietQuality               float64\n",
              "SleepQuality              float64\n",
              "PollutionExposure         float64\n",
              "PollenExposure            float64\n",
              "DustExposure              float64\n",
              "PetAllergy                  int64\n",
              "FamilyHistoryAsthma         int64\n",
              "HistoryOfAllergies          int64\n",
              "Eczema                      int64\n",
              "HayFever                    int64\n",
              "GastroesophagealReflux      int64\n",
              "LungFunctionFEV1          float64\n",
              "LungFunctionFVC           float64\n",
              "Wheezing                    int64\n",
              "ShortnessOfBreath           int64\n",
              "ChestTightness              int64\n",
              "Coughing                    int64\n",
              "NighttimeSymptoms           int64\n",
              "ExerciseInduced             int64\n",
              "Diagnosis                   int64\n",
              "DoctorInCharge             object\n",
              "Obesity                     int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PatientID</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ethnicity</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EducationLevel</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Current Smoker</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DietQuality</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SleepQuality</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PollutionExposure</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PollenExposure</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DustExposure</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PetAllergy</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FamilyHistoryAsthma</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HistoryOfAllergies</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Eczema</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HayFever</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GastroesophagealReflux</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LungFunctionFEV1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LungFunctionFVC</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wheezing</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ShortnessOfBreath</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ChestTightness</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coughing</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NighttimeSymptoms</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExerciseInduced</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diagnosis</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoctorInCharge</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obesity</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Load the trained models\n",
        "rf_model = joblib.load('RandomForest_Balanced_CAD_v1_model.pkl')\n",
        "lgb_model = joblib.load('LightGBM_CAD_v1_model.pkl')\n",
        "xgb_model = joblib.load('XGBoost_CAD_v1_model.pkl')\n",
        "\n",
        "# List of models and their names\n",
        "models = {\n",
        "    \"RandomForest\": rf_model,\n",
        "    \"LightGBM\": lgb_model,\n",
        "    \"XGBoost\": xgb_model\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_model_name = \"\"\n",
        "best_roc_auc = 0\n",
        "\n",
        "# Initialize variables for best model selection\n",
        "best_model = None\n",
        "best_model_name = \"\"\n",
        "best_roc_auc = 0\n",
        "\n",
        "# Use X_test and y_test to select the best model\n",
        "for name, model in models.items():\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "    if roc_auc > best_roc_auc:\n",
        "        best_roc_auc = roc_auc\n",
        "        best_model = model\n",
        "        best_model_name = name\n",
        "\n",
        "print(f\"Best model selected: {best_model_name} with ROC-AUC: {best_roc_auc:.2f}\")\n",
        "\n",
        "# Now proceed to apply the best model to the asthmadf dataset\n",
        "\n",
        "print(f\"Best model selected: {best_model_name} with ROC-AUC: {best_roc_auc:.2f}\")\n",
        "\n",
        "# Assuming the best model is selected or if you already know which one is the best:\n",
        "best_model = rf_model  # replace this with the selected best model\n",
        "\n",
        "# Apply the best model to the asthmadf dataset\n",
        "asthma_features = ['age', 'bmi', 'Current Smoker', 'gender', 'Obesity']\n",
        "asthmadf_X = asthmadf[asthma_features]\n",
        "\n",
        "# Handle missing values (use the same strategy used during training)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "asthmadf_X = pd.DataFrame(imputer.fit_transform(asthmadf_X), columns=asthma_features)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "asthmadf['Cad_Probability'] = best_model.predict_proba(asthmadf_X)[:, 1]\n",
        "asthmadf['Cad'] = (asthmadf['Cad_Probability'] > 0.5).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Save the adjusted predictions\n",
        "asthmadf.to_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/asthma_disease_CADPredictions.csv', index=False)\n",
        "\n",
        "print(\"Predictions and adjustments completed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q56ip7Io9HWF",
        "outputId": "750cf511-1a42-472e-c1f6-14c76dcfbbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model selected: LightGBM with ROC-AUC: 0.71\n",
            "Best model selected: LightGBM with ROC-AUC: 0.71\n",
            "Predictions and adjustments completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asthmaCaddf = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/asthma_disease_CADPredictions.csv')"
      ],
      "metadata": {
        "id": "NQBkbseK-k_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cad_distribution = asthmaCaddf['Cad'].value_counts(normalize=True)\n",
        "print(cad_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDg_Tiyf-scH",
        "outputId": "083781e6-696f-43b7-e506-9ca14b85e9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cad\n",
            "0    0.861204\n",
            "1    0.138796\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#alder pollen, birch pollen, grass pollen, mugworth pollen, olive pollen, ragweed pollen\n",
        "\n",
        "#ragweed pollen = distribution source https://www.meduniwien.ac.at/web/en/ueber-uns/news/2022/news-im-august-2022/ragweed-allergie-herkunftsort-und-umwelt-beeinflussen-aggressivitaet-der-pollen/\n",
        "#33 million Europeans suffer from ragweed allergy in 2022 / 447.03 millon = 7.38%\n",
        "\n",
        "#grass pollen: distribution source https://www.meduniwien.ac.at/web/en/about-us/news/detailsite/2018/news-jaenner-2018/first-vaccine-in-the-world-developed-against-grass-pollen-allergy/medicine-science/\n",
        "#400 million people world-wide in 2018 /7.594 million = 5.27%\n",
        "\n",
        "#mugwort pollen distribution source https://www.thermofisher.com/allergy/us/en/allergen-fact-sheets/mugwort.html 10-15% in EU\n",
        "\n",
        "#birch pollen distribution source https://www.meduniwien.ac.at/web/en/about-us/news/detailsite/apple-allergy-symptoms-may-be-significantly-reduced-in-future/ 4.73%\n",
        "\n",
        "#alder pollen distributioin source https://www.thermofisher.com/phadia/wo/en/resources/allergen-encyclopedia/t2.html 6-10%%\n",
        "\n",
        "#olive pollen allergy there are not sensible data on the distribution but it given the normal distribution oof the other allergies should be around 5-8%%\n",
        "\n",
        "#asthma allergy in Europe is 6.71% of the population sources European Lung Foundation (ELF): https://europeanlung.org/en/ Global Asthma Report: http://www.globalasthmareport.org/\n",
        "#studies have shown how asthma, eczema and pollen allergies are correlated thus having one or more of those sympthoms means that an individual will be more prone to have one or more of those conditions source https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5806141/"
      ],
      "metadata": {
        "id": "HPWbRl2fHfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/asthma_disease_CADPredictions.csv')\n",
        "\n",
        "# Define the distributions for each allergy\n",
        "prob_ragweed_pollen = 0.0738\n",
        "prob_grass_pollen = 0.0527\n",
        "prob_mugwort_pollen = 0.0527\n",
        "prob_birch_pollen = 0.125\n",
        "prob_alder_pollen = 0.08\n",
        "prob_olive_pollen = 0.07\n",
        "prob_asthma = 0.0671\n",
        "\n",
        "# Increased probabilities based on conditions\n",
        "prob_asthma_with_history = 0.60\n",
        "prob_pollen_with_eczema_or_asthma = 0.40\n",
        "\n",
        "# Initialize columns for the new allergies\n",
        "df['Ragweed_Pollen_Allergy'] = 0\n",
        "df['Grass_Pollen_Allergy'] = 0\n",
        "df['Mugwort_Pollen_Allergy'] = 0\n",
        "df['Birch_Pollen_Allergy'] = 0\n",
        "df['Alder_Pollen_Allergy'] = 0\n",
        "df['Olive_Pollen_Allergy'] = 0\n",
        "df['Asthma_Allergy'] = 0\n",
        "df['Eczema'] = 0\n",
        "\n",
        "# Assign allergies based on the probabilities\n",
        "for index, row in df.iterrows():\n",
        "    # Determine if the person has eczema\n",
        "    if np.random.rand() < prob_pollen_with_eczema_or_asthma:\n",
        "        df.at[index, 'Eczema'] = 1\n",
        "\n",
        "    # Determine if the person has asthma, with higher probability if there's a family history\n",
        "    if row['FamilyHistoryAsthma'] == 1:\n",
        "        if np.random.rand() < prob_asthma_with_history:\n",
        "            df.at[index, 'Asthma_Allergy'] = 1\n",
        "    else:\n",
        "        if np.random.rand() < prob_asthma:\n",
        "            df.at[index, 'Asthma_Allergy'] = 1\n",
        "\n",
        "    # Assign pollen allergies, with higher probability if the person has eczema or asthma\n",
        "    if df.at[index, 'Eczema'] == 1 or df.at[index, 'Asthma_Allergy'] == 1:\n",
        "        if np.random.rand() < prob_pollen_with_eczema_or_asthma:\n",
        "            if np.random.rand() < prob_ragweed_pollen:\n",
        "                df.at[index, 'Ragweed_Pollen_Allergy'] = 1\n",
        "            if np.random.rand() < prob_grass_pollen:\n",
        "                df.at[index, 'Grass_Pollen_Allergy'] = 1\n",
        "            if np.random.rand() < prob_mugwort_pollen:\n",
        "                df.at[index, 'Mugwort_Pollen_Allergy'] = 1\n",
        "            if np.random.rand() < prob_birch_pollen:\n",
        "                df.at[index, 'Birch_Pollen_Allergy'] = 1\n",
        "            if np.random.rand() < prob_alder_pollen:\n",
        "                df.at[index, 'Alder_Pollen_Allergy'] = 1\n",
        "            if np.random.rand() < prob_olive_pollen:\n",
        "                df.at[index, 'Olive_Pollen_Allergy'] = 1\n",
        "    else:\n",
        "        if np.random.rand() < prob_ragweed_pollen:\n",
        "            df.at[index, 'Ragweed_Pollen_Allergy'] = 1\n",
        "        if np.random.rand() < prob_grass_pollen:\n",
        "            df.at[index, 'Grass_Pollen_Allergy'] = 1\n",
        "        if np.random.rand() < prob_mugwort_pollen:\n",
        "            df.at[index, 'Mugwort_Pollen_Allergy'] = 1\n",
        "        if np.random.rand() < prob_birch_pollen:\n",
        "            df.at[index, 'Birch_Pollen_Allergy'] = 1\n",
        "        if np.random.rand() < prob_alder_pollen:\n",
        "            df.at[index, 'Alder_Pollen_Allergy'] = 1\n",
        "        if np.random.rand() < prob_olive_pollen:\n",
        "            df.at[index, 'Olive_Pollen_Allergy'] = 1\n",
        "\n",
        "    # Ensure that if a person has HayFever (value 1), they have at least one pollen allergy\n",
        "    if row['HayFever'] == 1:\n",
        "        if not (df.at[index, 'Ragweed_Pollen_Allergy'] == 1 or\n",
        "                df.at[index, 'Grass_Pollen_Allergy'] == 1 or\n",
        "                df.at[index, 'Mugwort_Pollen_Allergy'] == 1 or\n",
        "                df.at[index, 'Birch_Pollen_Allergy'] == 1 or\n",
        "                df.at[index, 'Alder_Pollen_Allergy'] == 1 or\n",
        "                df.at[index, 'Olive_Pollen_Allergy'] == 1):\n",
        "            # Randomly assign one pollen allergy if none are assigned yet\n",
        "            pollen_allergies = ['Ragweed_Pollen_Allergy', 'Grass_Pollen_Allergy', 'Mugwort_Pollen_Allergy',\n",
        "                                'Birch_Pollen_Allergy', 'Alder_Pollen_Allergy', 'Olive_Pollen_Allergy']\n",
        "            chosen_allergy = np.random.choice(pollen_allergies)\n",
        "            df.at[index, chosen_allergy] = 1\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/SmallDataset.csv', index=False)\n",
        "\n",
        "# Check the distribution of allergies in the dataframe\n",
        "distribution = {\n",
        "    'Ragweed_Pollen_Allergy': df['Ragweed_Pollen_Allergy'].mean(),\n",
        "    'Grass_Pollen_Allergy': df['Grass_Pollen_Allergy'].mean(),\n",
        "    'Mugwort_Pollen_Allergy': df['Mugwort_Pollen_Allergy'].mean(),\n",
        "    'Birch_Pollen_Allergy': df['Birch_Pollen_Allergy'].mean(),\n",
        "    'Alder_Pollen_Allergy': df['Alder_Pollen_Allergy'].mean(),\n",
        "    'Olive_Pollen_Allergy': df['Olive_Pollen_Allergy'].mean(),\n",
        "    'Asthma_Allergy': df['Asthma_Allergy'].mean(),\n",
        "    'Eczema': df['Eczema'].mean()\n",
        "}\n",
        "\n",
        "distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLpu3YMLbJQT",
        "outputId": "368992fa-8459-4ec1-e8e8-f47396eacc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ragweed_Pollen_Allergy': 0.07566889632107024,\n",
              " 'Grass_Pollen_Allergy': 0.07065217391304347,\n",
              " 'Mugwort_Pollen_Allergy': 0.07566889632107024,\n",
              " 'Birch_Pollen_Allergy': 0.1149665551839465,\n",
              " 'Alder_Pollen_Allergy': 0.07566889632107024,\n",
              " 'Olive_Pollen_Allergy': 0.0798494983277592,\n",
              " 'Asthma_Allergy': 0.23118729096989968,\n",
              " 'Eczema': 0.395066889632107}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/SmallDataset.csv')\n",
        "\n",
        "# Function to generate random date of birth based on age\n",
        "def generate_dob(age):\n",
        "    year_of_birth = datetime.now().year - age\n",
        "    # Generate random month\n",
        "    month = np.random.randint(1, 13)\n",
        "    # Generate random day based on the month and whether it's a leap year\n",
        "    if month == 2:  # February\n",
        "        if year_of_birth % 4 == 0 and (year_of_birth % 100 != 0 or year_of_birth % 400 == 0):\n",
        "            day = np.random.randint(1, 30)  # Leap year\n",
        "        else:\n",
        "            day = np.random.randint(1, 29)\n",
        "    elif month in [4, 6, 9, 11]:\n",
        "        day = np.random.randint(1, 31)  # April, June, September, November have 30 days\n",
        "    else:\n",
        "        day = np.random.randint(1, 32)  # Other months have 31 days\n",
        "    dob = datetime(year_of_birth, month, day).strftime('%Y-%m-%d')\n",
        "    return dob\n",
        "\n",
        "# Replace 'age' with 'date_of_birth'\n",
        "df['Date_of_Birth'] = df['age'].apply(generate_dob)\n",
        "df.drop(columns=['age'], inplace=True)\n",
        "\n",
        "# Drop specified columns\n",
        "columns_to_drop = ['Ethnicity', 'GastroesophagealReflux', 'LungFunctionFEV1', 'LungFunctionFVC',\n",
        "                   'Diagnosis', 'DoctorInCharge']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Round specified columns to one decimal point\n",
        "columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality', 'PollutionExposure',\n",
        "                    'PollenExposure', 'DustExposure']\n",
        "df[columns_to_round] = df[columns_to_round].round(1)\n",
        "\n",
        "# Save the modified dataframe to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/SmallDatasetV1.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the modified dataframe\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "CD0RqmhOh23_",
        "outputId": "582ec8c4-b7c5-4602-eb3a-63dc02ca9566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PatientID  gender  EducationLevel   bmi  Current Smoker  PhysicalActivity  \\\n",
              "0       5034       0               0  15.8               0               0.9   \n",
              "1       5035       1               2  22.8               0               5.9   \n",
              "2       5036       0               1  18.4               0               6.7   \n",
              "3       5037       1               1  38.5               0               1.4   \n",
              "4       5038       0               3  19.3               0               4.6   \n",
              "\n",
              "   DietQuality  SleepQuality  PollutionExposure  PollenExposure  ...  \\\n",
              "0          5.5           8.7                7.4             2.9  ...   \n",
              "1          6.3           5.2                2.0             7.5  ...   \n",
              "2          9.2           6.8                1.5             1.4  ...   \n",
              "3          5.8           4.3                0.6             7.6  ...   \n",
              "4          3.1           9.6                1.0             3.0  ...   \n",
              "\n",
              "   Cad_Probability  Cad  Ragweed_Pollen_Allergy  Grass_Pollen_Allergy  \\\n",
              "0             0.43    0                       0                     0   \n",
              "1             0.04    0                       0                     0   \n",
              "2             0.16    0                       0                     0   \n",
              "3             0.12    0                       1                     0   \n",
              "4             0.13    0                       0                     0   \n",
              "\n",
              "   Mugwort_Pollen_Allergy  Birch_Pollen_Allergy  Alder_Pollen_Allergy  \\\n",
              "0                       0                     0                     0   \n",
              "1                       0                     0                     0   \n",
              "2                       0                     1                     0   \n",
              "3                       0                     0                     0   \n",
              "4                       1                     0                     0   \n",
              "\n",
              "   Olive_Pollen_Allergy  Asthma_Allergy  Date_of_Birth  \n",
              "0                     0               0     1961-12-19  \n",
              "1                     0               1     1998-03-30  \n",
              "2                     0               1     1967-02-03  \n",
              "3                     0               0     1984-08-26  \n",
              "4                     0               0     1963-04-20  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-927549f0-bbea-487c-ab55-4a9e960d4a52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>gender</th>\n",
              "      <th>EducationLevel</th>\n",
              "      <th>bmi</th>\n",
              "      <th>Current Smoker</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>DietQuality</th>\n",
              "      <th>SleepQuality</th>\n",
              "      <th>PollutionExposure</th>\n",
              "      <th>PollenExposure</th>\n",
              "      <th>...</th>\n",
              "      <th>Cad_Probability</th>\n",
              "      <th>Cad</th>\n",
              "      <th>Ragweed_Pollen_Allergy</th>\n",
              "      <th>Grass_Pollen_Allergy</th>\n",
              "      <th>Mugwort_Pollen_Allergy</th>\n",
              "      <th>Birch_Pollen_Allergy</th>\n",
              "      <th>Alder_Pollen_Allergy</th>\n",
              "      <th>Olive_Pollen_Allergy</th>\n",
              "      <th>Asthma_Allergy</th>\n",
              "      <th>Date_of_Birth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5034</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>8.7</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>...</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1961-12-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5035</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>6.3</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1998-03-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5036</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1967-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5037</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1984-08-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5038</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>19.3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>9.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1963-04-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-927549f0-bbea-487c-ab55-4a9e960d4a52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-927549f0-bbea-487c-ab55-4a9e960d4a52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-927549f0-bbea-487c-ab55-4a9e960d4a52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c686ec0-4ab7-41cd-bc89-16a60bd0c6fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c686ec0-4ab7-41cd-bc89-16a60bd0c6fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c686ec0-4ab7-41cd-bc89-16a60bd0c6fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ctgan import CTGAN\n",
        "\n",
        "# Load the dataset\n",
        "asthmaCaddf = pd.read_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/SmallDatasetV1.csv')\n",
        "\n",
        "def extract_features(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    features = df.columns.tolist()\n",
        "    return features\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/SmallDatasetV1.csv'\n",
        "features = extract_features(file_path)\n",
        "print(features)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize CTGAN\n",
        "ctgan = CTGAN(verbose=True)\n",
        "\n",
        "# Fit CTGAN to the data\n",
        "ctgan.fit(asthmaCaddf, features, epochs=5000)  # Adjust the number of epochs as needed\n",
        "\n",
        "# Generate 10000 synthetic samples\n",
        "samples = ctgan.sample(10000)\n",
        "\n",
        "# Post-process the synthetic data to ensure 'gender' is correctly encoded\n",
        "samples['gender'] = samples['gender'].clip(0, 1).round().astype(int)\n",
        "\n",
        "# Optionally, print or inspect the first few rows of the synthetic data\n",
        "samples.to_csv('/content/drive/MyDrive/Big Data Technologies/datasets/RawDatasets/FinalDatasetSynthetic.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbyrzRj1aq4q",
        "outputId": "e1dac645-83d0-4004-f6c8-cf4d991450b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['PatientID', 'gender', 'EducationLevel', 'bmi', 'Current Smoker', 'PhysicalActivity', 'DietQuality', 'SleepQuality', 'PollutionExposure', 'PollenExposure', 'DustExposure', 'PetAllergy', 'FamilyHistoryAsthma', 'HistoryOfAllergies', 'Eczema', 'HayFever', 'Wheezing', 'ShortnessOfBreath', 'ChestTightness', 'Coughing', 'NighttimeSymptoms', 'ExerciseInduced', 'Obesity', 'Cad_Probability', 'Cad', 'Ragweed_Pollen_Allergy', 'Grass_Pollen_Allergy', 'Mugwort_Pollen_Allergy', 'Birch_Pollen_Allergy', 'Alder_Pollen_Allergy', 'Olive_Pollen_Allergy', 'Asthma_Allergy', 'Date_of_Birth']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gen. (0.00) | Discrim. (0.00):   0%|          | 0/5000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Gen. (-1.16) | Discrim. (-0.16):  92%|█████████▏| 4595/5000 [1:20:08<06:55,  1.03s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLoMxt9k1-KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7VShzBG2Fb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
